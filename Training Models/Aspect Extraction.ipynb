{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bddf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638e1841",
   "metadata": {},
   "source": [
    "### Loading & Preprocessig Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb12b8e",
   "metadata": {},
   "source": [
    "##### 1. ABSA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d592ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_absa_dataset(folder_path):\n",
    "  data = []\n",
    "  for root, _, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "      if file.endswith(\".json\"):\n",
    "        with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as f:\n",
    "          content = json.load(f)\n",
    "          for entry in content:\n",
    "            text = \" \".join(entry[\"token\"])\n",
    "            aspects = []\n",
    "            for asp in entry.get(\"aspects\", []):\n",
    "              term = \" \".join(asp[\"term\"])\n",
    "              # If from/to not present, try to find in text\n",
    "              try:\n",
    "                from_idx = text.index(term)\n",
    "                to_idx = from_idx + len(term)\n",
    "              except ValueError:\n",
    "                from_idx, to_idx = -1, -1\n",
    "              aspects.append({\"term\": term, \"from\": from_idx, \"to\": to_idx})\n",
    "            data.append({\n",
    "              \"text\": text,\n",
    "              \"aspects\": aspects,\n",
    "              \"no_aspect_mentioned\": len(aspects) == 0\n",
    "            })\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0cc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "absa_data = preprocess_absa_dataset(r\"C:\\Users\\HP\\Downloads\\ABSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d6ebda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35804\n",
      "{'text': 'The flavors are very fresh and pretty inobtrusive , nothing flashy .', 'aspects': [{'term': 'flavors', 'from': 4, 'to': 11}], 'no_aspect_mentioned': False}\n"
     ]
    }
   ],
   "source": [
    "print(len(absa_data))\n",
    "print(absa_data[15100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f7bdec",
   "metadata": {},
   "source": [
    "##### 2. Semeval2014 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb938b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_semeval_dataset(folder_path):\n",
    "  data = []\n",
    "  for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "      df = pd.read_csv(os.path.join(folder_path, file))\n",
    "      for _, row in df.iterrows():\n",
    "        text = row[\"Sentence\"]\n",
    "        aspects = []\n",
    "        if pd.notna(row[\"Aspect Term\"]):\n",
    "          aspects.append({\n",
    "            \"term\": str(row[\"Aspect Term\"]),\n",
    "            \"from\": int(row[\"from\"]),\n",
    "            \"to\": int(row[\"to\"])\n",
    "          })\n",
    "        # Check if text already exists in the previous row\n",
    "        try:\n",
    "          if data[-1][\"text\"] == text:\n",
    "            data[-1][\"aspects\"].extend(aspects)\n",
    "            continue\n",
    "        except IndexError:\n",
    "          pass\n",
    "        data.append({\n",
    "          \"text\": text,\n",
    "          \"aspects\": aspects,\n",
    "          \"no_aspect_mentioned\": len(aspects) == 0\n",
    "        })\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd84411",
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_data = preprocess_semeval_dataset(r\"C:\\Users\\HP\\Downloads\\Semeval2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9eb3a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4073\n",
      "{'text': 'Love the food quality here but service was terrible', 'aspects': [{'term': 'food', 'from': 9, 'to': 13}, {'term': 'service', 'from': 29, 'to': 36}], 'no_aspect_mentioned': False}\n"
     ]
    }
   ],
   "source": [
    "print(len(semeval_data))\n",
    "print(semeval_data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f916181",
   "metadata": {},
   "source": [
    "##### 3. No Aspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdffa91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_no_aspect_dataset(csv_path):\n",
    "  df = pd.read_csv(csv_path)\n",
    "  data = []\n",
    "  for _, row in df.iterrows():\n",
    "    data.append({\n",
    "      \"text\": row[\"text\"],\n",
    "      \"aspects\": [],\n",
    "      \"no_aspect_mentioned\": True\n",
    "    })\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00d886e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "noaspect_data = preprocess_no_aspect_dataset(r\"C:\\Users\\HP\\Downloads\\aspect_training_no_aspect.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90ab6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noaspect_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1612e",
   "metadata": {},
   "source": [
    "### Tokenization & Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d96ce25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40690"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = absa_data + semeval_data + noaspect_data\n",
    "np.random.shuffle(full_data)\n",
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "576eec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108effe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQMBJREFUeJzt3Qd8FNX+//8PEHov0qQKSi+CiAiiFEGMCIJekC4IFwSUXq5IVaqAKE1FAQWkfC8oRXqT3pReBAQBqYr0DvN7fM79z/53QxIS3GQ3Oa/n47Eku3Mye2Zm2X3vKTMJHMdxBAAAwGIJA10BAACAQCMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxAh3ujbt68kSJAgVp7rhRdeMDfXqlWrzHP/3//9X6w8f7NmzSRPnjwSzK5cuSJvv/22ZM2a1eybDh06xMrx//PPP2P0eSJ63timz6nPjdgXqNcaYhaBCEFp0qRJ5g3HvSVLlkyyZ88u1atXl08//VQuX77sl+c5efKkeXPbvn27BJtgrltUDBw40BzHNm3ayLfffiuNGzeO8IPlQTfv8Imo0X0WlX3rz1Clx/z777+PUtmjR4+a5//4448lWEVnexD3hQS6AkBk+vfvL3nz5pXbt2/L6dOnTUuMtjSMGDFC5s6dK8WLF/eU7dWrl/To0SPaoaNfv36mtaVkyZJR/rslS5ZITIusbl9++aXcu3dPgtmKFSvkmWeekT59+kRYpk6dOpI/f36fViUNUK+99ppZ5sqSJYsEq4d53cWG999/37TQubZs2WK+TPznP/+RQoUKeR73/j/kjwDx+uuvS+3atSU+iG/bg8gRiBDUatSoIU899ZTnfs+ePc0H7SuvvCKvvvqq7Nu3T5InT26WhYSEmFtMunbtmqRIkUKSJEkigZQ4cWIJdmfPnpXChQtHWkY/jL0/kLULQgORPtaoUSOJC2LjdfcwXnzxRZ/72sqqgUgfp8UNuB9dZohzKleuLB988IH8/vvvMmXKlEjHcixdulQqVKgg6dKlk1SpUkmBAgXMN2SlrU1lypQxv7/11lueLgTt5lH6oVG0aFHZtm2bVKxY0QQh92/DjiFy3b1715TRcTMpU6Y0oe348eM+ZbTFR8cAheW9zgfVLbwxRFevXpXOnTtLzpw5JWnSpGZbtTvCcRyfcrqedu3ama4A3T4tW6RIEVm0aFGUg06LFi1Mq41+yJYoUUImT55833iqI0eOyIIFCzx11y6Sh6Uh+LnnnjP7VI9lrVq1TBh+EH2NaAuUbueZM2fMYxcuXDCtjO5+0uVDhgzxaXHz7s754osvJF++fKasHhNtafEW9nWnxyYq3VM3b940rWf6/LpurU+3bt3M4970fseOHeWRRx6R1KlTm9fUiRMnxF8WLlzo2be6/tDQUNmzZ4/Pvk+YMKH07t3b5++mTZtmtmncuHHmvv6ur0F9LbjbG97rPLqiup+i87rW16h+0dLXrx7bzz///L7jGJXt0deSPqavybRp05r/q/qlKarvQQguwfe1BogCHY+ibyraddWyZctwy+iburYkaWuDdr3pG+ShQ4dk3bp1Zrl2G+jj+kbfqlUr86Ggnn32Wc86/vrrL9NKVb9+fdNi8aCum48++si8cXbv3t0Eh08++USqVq1qxgG5LVlREZW6edPQox+UK1euNGFFu9gWL14sXbt2lT/++ENGjhzpU37t2rUye/Zseeedd8yHoLYc1K1bV44dOyYZM2aMsF7Xr183oU33o374aHfmrFmzzIeCfji89957pu46Zkg/xHPkyGFCmtIP9IexbNkycwwee+wx86Gldfjss8+kfPny8vPPP0c4uPzw4cMmPGfIkMF8KGXKlMl8WD3//PNmn/z73/+WXLlyyfr1603L46lTp8zxCvuhr+PVtKwe16FDh5quvN9++y3CVjotq8fcm34oT506VTJnzmzua/jS46XHQY+v7rNdu3aZ4/Trr7/6jFvRbi8N/g0aNDDHXwOKhhZ/0OPUtGlTMzZPQ6HuHw04+gH+yy+/mH2r+1BfJ4MGDTJdR6VKlTL7qn379mY7W7du7VmX1vXpp58226Q0bPwT0dlPUX1d63a99NJLki1bNtMlrV9i9P9a2NdnVLbnX//6l/k/oPtGX4sTJkwwx1j3ZVTegxBkHCAITZw4UZs1nC1btkRYJm3atM6TTz7pud+nTx/zN66RI0ea++fOnYtwHbp+LaPPF9bzzz9vlo0fPz7cZXpzrVy50pR99NFHnUuXLnkenzlzpnl81KhRnsdy587tNG3a9IHrjKxu+ve6Htf3339vyn744Yc+5V5//XUnQYIEzqFDhzyPabkkSZL4PLZjxw7z+GeffeZE5pNPPjHlpkyZ4nns1q1bTrly5ZxUqVL5bLvWLzQ01IkOPVa6fj2WrpIlSzqZM2d2/vrrL5/6JkyY0GnSpMl9x1/XsW/fPid79uxOmTJlnPPnz3vKDBgwwEmZMqXz66+/+jxvjx49nESJEjnHjh0z948cOWLWlTFjRp+//+GHH8zj8+bNu+95I3Lw4EHzWn3xxRedO3fumMe+/fZbU/81a9b4lNXXmq5r3bp15v727dvN/XfeecenXIMGDe7bTw8ya9Ys8zf6WlWXL1920qVL57Rs2dKn3OnTp019vR+/evWqkz9/fqdIkSLOjRs3zHFNkyaN8/vvv/v8re7b8F7b4XH38bBhwyIsE9X9FJ3Xdc2aNZ0UKVI4f/zxh88xCgkJue84RrQ97jFv3ry5z+Ovvfaaec1E5z0IwYMuM8RZ2vwc2WwzbaJWP/zww0MPQNZvdNoMHlVNmjQx30xdOiBTv4n++OOPEpN0/YkSJZJ3333X53FtndHPCu0W8abf7L2/7eo32DRp0piWjwc9j3YHvvnmm57HtKVEn1cHRK9evVr8SVsitHVNW6C0pce7vjoWJrz9unv3btMKpK0b2rqUPn16zzJtzdLWNn1Mxyu5N90f2lLw008/+ayrXr16Pn/vttQ9aD+5tMtFB4jrOr777jtzjNx6aGtHwYIFfeqhrTFKW/qUu31hj6s/TmGgrWbaqqfH0rsOWseyZct66qC0u1i7a7WbUruPtStUW2m0hS0mRXU/RfV1rcdYXxPa0qWzVl3aHaetkNHlto55vz60VfnSpUt+ew9C7KHLDHGWfgC7XRDh0Q8zbcLWZm+dBVSlShXT3aEhRcdERMWjjz4arQHUjz/+uM997WbRN9t/Mn4mKnSsjL7Be4cx5c4m0uXewvsg0w/tv//++4HPo9sYdv9F9Dz/lLs+HXcRlj6ndgtq6NDxL66aNWuark1dpqHZ28GDB2Xnzp0Rdt9pN2dk+8kNRw/aTy7tztWuO+2W8+6K1HpouHhQPXT7dV+H7aoJb39El9ZBueEiLA0S3rSLUge8jxkzxnSxNW/e/B/XISp1jMp+iurrWstrl6v3zEZXeI89SGSvD91//ngPQuwhECFO0kGlFy9ejPRNTMfs6Dd+/Rap32h1HMeMGTPMB4COPXK/rUcmOuN+oiqik/jpt9eo1MkfInqesAOw4yIdM6IDYXXMjo7n8abf0rVlSQflhueJJ57w234aNWqUaRXS8T9hT5ug9ShWrJg5fUR4dOBwTHNbLHSsjLb6hRV25pwOYtbByEpDnjvjMqbrGJ39FNuv6wc9nz/egxB7CESIk/RNXOk31cjotzD9VqY3fVPV84ro+Vn0DUqb1/19hmH3W7f3G6MOovSeWq7fIrWrIixtDdCBw67o1C137tymK0C7EL1bifbv3+9Z7g+6Hm1h0Q8q72+4/n4e7+dTBw4cuG+ZPqcOlPZuHVLDhg0zH+buwFodjOzSlhZtWQw76Nnf1qxZI126dDFdWw0bNrxvudZjx44d5nUZ2XHW7dd9rQHEu1UovP0RXW6rk7ayRmV/6Ewvba3RmXc6aUBbPHTQsjd//3+K6n6KKt1WnVmm/yfDCu8xfzzng96DEDxos0Oco7NsBgwYYGZ3hPdh4zp//vx9j7nf1N0pu+6HaXgB5WF88803PuOa9FIeOg7Ge3yCvslv3LhRbt265Xls/vz5903Pj07dXn75ZdPCNHr0aJ/HdZyHvqk/zPiIiJ5HT5Cp33Jdd+7cMbO+tHtKx+74k46/0mOmLT7e+0HHCek3bK1PWLq9OlVeuyV0BpWewNN7VtCGDRtMd1pYun7dln9Kj7c+j87U0nAWHl2uM930BJthaZeOdgMq97iFDR5hZ8M9DP0yod06+gGtJz4N69y5c57fN23aZIKQBjwdl6azF/W1FnbMmL5m/fV/KTr7Kaq0RUZDiM5O0xOfeoehsOPs/LE9UXkPQvCghQhBTd+ktCVAP6j0PDIahnQwqH5z1g86/bYXEZ3mqs3VOkVZy+v4gbFjx5qp4Pph5YYTHfg4fvx405qgb4A6oFTD1sPQgb+6bh2IrfXVDy7t1vM+NYCOJ9CgpFN/9Q1fv/1rt0rYcSLRqZuOm6lUqZL55qnjlfTcQBoYdDCnfoj90+nPLp1+rOds0UHOen4mHbis26LTiHVbw45h8gcNFRoMypUrZ04p4E671/O+RHTZCf1WrvtUB8/qPtbBydpNoR/k+rrRqdC6DaVLlzYfqjqVW7dD9522Ov0TOgBaw4R2y02fPj3cE1HqaSNmzpxpBuVqS4GOz9FAq691fVwDm54nRz88ddCzvm61i1in3S9fvjzc1ozo0jCkU+y1LjqVXk8toWN1dIq6du9onTT03LhxwwRLHTump5VQOl193rx55nWu+84N77o/taVSW0J0TJu+VvU1GxndHn2OsPTYRXU/RYe+ZvT/hjsmyv0ioecuCnuZnIfZnui+ByGIBHqaGxDZtHv3ptNps2bNaqYu6xR27+ndEU1/Xr58uVOrVi0z/Vr/Xn+++eab90251qnUhQsX9ky7dae56xR4nWYcnoim3X/33XdOz549zTTx5MmTm+nJYacmq+HDh5sp+kmTJnXKly/vbN269b51Rla3sNPu3WnUHTt2NNuZOHFi5/HHHzdTmu/du+dTTtfTtm3b++oU0ekAwjpz5ozz1ltvOZkyZTL7tVixYuGeGsBf0+7VsmXLzH7SfarTvXXq9N69e33KeE+7d127ds3sUz0lwMaNGz37SY+RTiPX+ut2PPvss87HH39sTiHwoCnhYesX9nXnnq4hvJv33+lzDRkyxLzG9HWQPn16p3Tp0k6/fv2cixcvespdv37deffdd810bp0Grtt+/Pjxfzzt3qX3q1evbqbaJ0uWzMmXL5/TrFkz85pU+prSUxJs2rTJ5+90ub4u27Rp43ls//79TsWKFc1x0ueK7PXk7uOIbjrlPjr7KTqva31v0FN26PHX7Z0wYYLTuXNns/3eItqe8F5r3u9bum3ReQ9CcEig/wQ6lAEAEEjaIqUnUgw7DhD2YAwRAMAq2u3qTUOQdqtyjTe70UIEALCKDtbXMWQ6q1Nnd+pYKh3krJf1CHsuMdiDQdUAAKvohAY9R5TOmNSz0euAfZ1tRxiyGy1EAADAeowhAgAA1iMQAQAA6zGGKAr01Pl6VlM96Zy/T00PAABiho4K0qsH6Ik1H3RBXQJRFGgYio2LLQIAAP/TSyPpGcIjQyCKAvdyBLpD9XT3AAAg+F26dMk0aETlskIEoihwu8k0DBGIAACIW6Iy3IVB1QAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegENROPGjZPixYt7zgBdrlw5WbhwoWf5jRs3pG3btpIxY0ZJlSqV1K1bV86cOeOzjmPHjkloaKikSJFCMmfOLF27dpU7d+74lFm1apWUKlVKkiZNKvnz55dJkybF2jYCAIDgF9BApBdaGzx4sGzbtk22bt0qlStXllq1asmePXvM8o4dO8q8efNk1qxZsnr1anOR1Tp16nj+/u7duyYM3bp1S9avXy+TJ082Yad3796eMkeOHDFlKlWqJNu3b5cOHTrI22+/LYsXLw7INgMAgOCTwHEcR4JIhgwZZNiwYfL666/LI488ItOmTTO/q/3790uhQoVkw4YN8swzz5jWpFdeecUEpSxZspgy48ePl+7du8u5c+ckSZIk5vcFCxbI7t27Pc9Rv359uXDhgixatCjKF4dLmzatXLx4kWuZAQAQR0Tn8ztoxhBpa8/06dPl6tWrputMW41u374tVatW9ZQpWLCg5MqVywQipT+LFSvmCUOqevXqZge4rUxaxnsdbhl3HeG5efOmWYf3DQAAxF8BD0S7du0y44N0fE/r1q1lzpw5UrhwYTl9+rRp4UmXLp1PeQ0/ukzpT+8w5C53l0VWRkPO9evXw63ToEGDTKJ0bzlz5vTrNgMAgOAS8EBUoEABM7Zn06ZN0qZNG2natKns3bs3oHXq2bOnaV5zb8ePHw9ofQAAQMwKkQDTViCd+aVKly4tW7ZskVGjRkm9evXMYGkd6+PdSqSzzLJmzWp+15+bN2/2WZ87C827TNiZaXpf+xKTJ08ebp20tUpv+Gfy9FjwwDJHB4fGSl0AAAjqFqKw7t27Z8bwaDhKnDixLF++3LPswIEDZpq9jjFS+lO73M6ePesps3TpUhN2tNvNLeO9DreMuw4AAICQQHdN1ahRwwyUvnz5splRpucM0inxOnanRYsW0qlTJzPzTENO+/btTZDRGWaqWrVqJvg0btxYhg4dasYL9erVy5y7yG3h0XFJo0ePlm7duknz5s1lxYoVMnPmTDPzDAAAIOCBSFt2mjRpIqdOnTIBSE/SqGHoxRdfNMtHjhwpCRMmNCdk1FYjnR02duxYz98nSpRI5s+fb8YeaVBKmTKlGYPUv39/T5m8efOa8KPnNNKuOD330YQJE8y6AAAAgvI8RMGI8xA9HMYQAQACKU6ehwgAACBQCEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9UICXQHYLU+PBQ8sc3RwaKzUBQBgLwIRgh6hCQAQ0+gyAwAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPVCAl0BID7K02PBA8scHRwaK3UBADwYgQjWIKQAACJClxkAALAeLURADLQ0AQDiFlqIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsF9BANGjQIClTpoykTp1aMmfOLLVr15YDBw74lHnhhRckQYIEPrfWrVv7lDl27JiEhoZKihQpzHq6du0qd+7c8SmzatUqKVWqlCRNmlTy588vkyZNipVtRNybUv+gGwAg/gloIFq9erW0bdtWNm7cKEuXLpXbt29LtWrV5OrVqz7lWrZsKadOnfLchg4d6ll29+5dE4Zu3bol69evl8mTJ5uw07t3b0+ZI0eOmDKVKlWS7du3S4cOHeTtt9+WxYsXx+r2AgCA4BTQEzMuWrTI574GGW3h2bZtm1SsWNHzuLb8ZM2aNdx1LFmyRPbu3SvLli2TLFmySMmSJWXAgAHSvXt36du3ryRJkkTGjx8vefPmleHDh5u/KVSokKxdu1ZGjhwp1atXj+GtBAAAwS6oxhBdvHjR/MyQIYPP41OnTpVMmTJJ0aJFpWfPnnLt2jXPsg0bNkixYsVMGHJpyLl06ZLs2bPHU6Zq1ao+69Qy+nh4bt68af7e+wYAAOKvoLl0x71790xXVvny5U3wcTVo0EBy584t2bNnl507d5qWHx1nNHv2bLP89OnTPmFIufd1WWRlNOhcv35dkidPft/Ypn79+sXYtgIAgOASNIFIxxLt3r3bdGV5a9Wqled3bQnKli2bVKlSRQ4fPiz58uWLkbpoK1SnTp089zU45cyZM0aeCwAABF5QdJm1a9dO5s+fLytXrpQcOXJEWrZs2bLm56FDh8xPHVt05swZnzLufXfcUURl0qRJc1/rkNKZaLrM+wYAAOKvgAYix3FMGJozZ46sWLHCDHx+EJ0lprSlSJUrV0527dolZ8+e9ZTRGWsaYgoXLuwps3z5cp/1aBl9HAAAIGGgu8mmTJki06ZNM+ci0rE+etNxPUq7xXTGmM46O3r0qMydO1eaNGliZqAVL17clNFp+hp8GjduLDt27DBT6Xv16mXWrS09Ss9b9Ntvv0m3bt1k//79MnbsWJk5c6Z07NgxkJsPAACCREAD0bhx48zMMj35orb4uLcZM2aY5TplXqfTa+gpWLCgdO7cWerWrSvz5s3zrCNRokSmu01/aotPo0aNTGjq37+/p4y2PC1YsMC0CpUoUcJMv58wYQJT7gEAQOAHVWuXWWR0ILOevPFBdBbajz/+GGkZDV2//PJLtOuI8HHG5uDZz0cHh8ZKXQAgPguKQdUAAACBRCACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgvZBAVwDAP5Onx4IHljk6ODRW6gIAcRUtRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoBDUSDBg2SMmXKSOrUqSVz5sxSu3ZtOXDggE+ZGzduSNu2bSVjxoySKlUqqVu3rpw5c8anzLFjxyQ0NFRSpEhh1tO1a1e5c+eOT5lVq1ZJqVKlJGnSpJI/f36ZNGlSrGwjAAAIfgENRKtXrzZhZ+PGjbJ06VK5ffu2VKtWTa5eveop07FjR5k3b57MmjXLlD958qTUqVPHs/zu3bsmDN26dUvWr18vkydPNmGnd+/enjJHjhwxZSpVqiTbt2+XDh06yNtvvy2LFy+O9W0GAADBJySQT75o0SKf+xpktIVn27ZtUrFiRbl48aJ89dVXMm3aNKlcubIpM3HiRClUqJAJUc8884wsWbJE9u7dK8uWLZMsWbJIyZIlZcCAAdK9e3fp27evJEmSRMaPHy958+aV4cOHm3Xo369du1ZGjhwp1atXD8i2AwCA4BFUY4g0AKkMGTKYnxqMtNWoatWqnjIFCxaUXLlyyYYNG8x9/VmsWDEThlwaci5duiR79uzxlPFeh1vGXUdYN2/eNH/vfQMAAPFX0ASie/fuma6s8uXLS9GiRc1jp0+fNi086dKl8ymr4UeXuWW8w5C73F0WWRkNOtevXw93bFPatGk9t5w5c/p5awEAQDAJmkCkY4l2794t06dPD3RVpGfPnqa1yr0dP3480FUCAADxdQyRq127djJ//nz56aefJEeOHJ7Hs2bNagZLX7hwwaeVSGeZ6TK3zObNm33W585C8y4Tdmaa3k+TJo0kT578vvroTDS9AQAAOwS0hchxHBOG5syZIytWrDADn72VLl1aEidOLMuXL/c8ptPydZp9uXLlzH39uWvXLjl79qynjM5Y07BTuHBhTxnvdbhl3HUAAAC7hQS6m0xnkP3www/mXETumB8dt6MtN/qzRYsW0qlTJzPQWkNO+/btTZDRGWZKp+lr8GncuLEMHTrUrKNXr15m3W4rT+vWrWX06NHSrVs3ad68uQlfM2fOlAULFgRy8wEAQJAIaAvRuHHjzBidF154QbJly+a5zZgxw1NGp8a/8sor5oSMOhVfu79mz57tWZ4oUSLT3aY/NSg1atRImjRpIv379/eU0ZYnDT/aKlSiRAkz/X7ChAlMuQcAAIFvIdIuswdJliyZjBkzxtwikjt3bvnxxx8jXY+Grl9++eWh6gkAAOK3oJllBgAAECgEIgAAYL2gmHaP2JOnx4MHkh8dHBordQEAIFjQQgQAAKxHIAIAANajywywAF2lABA5WogAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFjvoQLRb7/95v+aAAAAxKVAlD9/fqlUqZJMmTJFbty44f9aAQAABHsg+vnnn6V48eLSqVMnyZo1q/z73/+WzZs3+792AAAAwRqISpYsKaNGjZKTJ0/K119/LadOnZIKFSpI0aJFZcSIEXLu3Dn/1xQAACAYB1WHhIRInTp1ZNasWTJkyBA5dOiQdOnSRXLmzClNmjQxQQkAACBeB6KtW7fKO++8I9myZTMtQxqGDh8+LEuXLjWtR7Vq1fJfTQEAAILpWmYafiZOnCgHDhyQl19+Wb755hvzM2HC/+WrvHnzyqRJkyRPnjz+ri8AAEBwBKJx48ZJ8+bNpVmzZqZ1KDyZM2eWr7766p/WDwAAIDgD0cGDBx9YJkmSJNK0adOHWT0AAEDwjyHS7jIdSB2WPjZ58mR/1AsAACC4A9GgQYMkU6ZM4XaTDRw40B/1AgAACO5AdOzYMTNwOqzcuXObZQAAAPE+EGlL0M6dO+97fMeOHZIxY0Z/1AsAACC4A9Gbb74p7777rqxcuVLu3r1rbitWrJD33ntP6tev7/9aAgAABNssswEDBsjRo0elSpUq5mzV6t69e+bs1IwhAgAAVgQinVI/Y8YME4y0myx58uRSrFgxM4YIAADAikDkeuKJJ8wNAADAukCkY4b00hzLly+Xs2fPmu4ybzqeCAAAIF4HIh08rYEoNDRUihYtKgkSJPB/zQAAAII5EE2fPl1mzpxpLugKAABg5bR7HVSdP39+/9cGAAAgrgSizp07y6hRo8RxHP/XCAAAIC50ma1du9aclHHhwoVSpEgRSZw4sc/y2bNn+6t+AAAAwRmI0qVLJ6+99pr/awMAABBXAtHEiRP9XxMAAIC4NIZI3blzR5YtWyaff/65XL582Tx28uRJuXLlij/rBwAAEJwtRL///ru89NJLcuzYMbl586a8+OKLkjp1ahkyZIi5P378eP/XFAAAIJhaiPTEjE899ZT8/fff5jpmLh1XpGevBgAAiPctRGvWrJH169eb8xF5y5Mnj/zxxx/+qhsAAEDwthDptcv0emZhnThxwnSdAQAAxPtAVK1aNfnkk0889/VaZjqYuk+fPlzOAwAA2NFlNnz4cKlevboULlxYbty4IQ0aNJCDBw9KpkyZ5LvvvvN/LQEAAIItEOXIkUN27NhhLvK6c+dO0zrUokULadiwoc8gawAAgHgbiMwfhoRIo0aN/FsbAACAuBKIvvnmm0iXN2nS5GHrAwAAEDcCkZ6HyNvt27fl2rVrZhp+ihQpCEQAACD+zzLTEzJ633QM0YEDB6RChQoMqgYAAPZcyyysxx9/XAYPHnxf61FkfvrpJ6lZs6Zkz57dTN3//vvvfZY3a9bMPO5900uGeDt//rwZzJ0mTRpJly6dGdwd9npqOvD7ueeek2TJkknOnDll6NCh/3BrAQBAfOK3QOQOtNYLvEbV1atXpUSJEjJmzJgIy2gAOnXqlOcWtgVKw9CePXtk6dKlMn/+fBOyWrVq5Vl+6dIlc96k3Llzy7Zt22TYsGHSt29f+eKLLx5yKwEAQHzzUGOI5s6d63PfcRwTVkaPHi3ly5eP8npq1KhhbpFJmjSpZM2aNdxl+/btk0WLFsmWLVvMtdXUZ599Zk4O+fHHH5uWp6lTp8qtW7fk66+/NmOcihQpItu3b5cRI0b4BCcAAGCvhwpEtWvX9rmvXVmPPPKIVK5c2Zy00Z9WrVolmTNnlvTp05v1f/jhh5IxY0azbMOGDaabzA1DqmrVqpIwYULZtGmTudislqlYsaLPddf0pJJDhgwx4590vWHdvHnT3LxbmQAAQPwV8rDXMosN2l1Wp04dyZs3rxw+fFj+85//mBYlDTmJEiWS06dPm7AUttsuQ4YMZpnSn/r33rJkyeJZFl4gGjRokPTr1y9Gtw0AAMSDEzPGhvr163t+L1asmBQvXlzy5ctnWo2qVKkSY8/bs2dP6dSpk08LkQ7GBgAA8dNDBSLvsPAgOlbHXx577DFzvbRDhw6ZQKRji86ePetT5s6dO2bmmTvuSH+eOXPGp4x7P6KxSTpuSW8AAMAODxWIfvnlF3PTEzIWKFDAPPbrr7+abqxSpUr5jC3ypxMnTshff/0l2bJlM/fLlSsnFy5cMLPHSpcubR5bsWKF6dIrW7asp8z7779v6po4cWLzmM5I03qH110GAADs81CBSM8dlDp1apk8ebInVOgA5bfeesuc76dz585RWo+eL0hbe1xHjhwxM8B0DJDedBxP3bp1TUuOjiHq1q2b5M+f3wyKVoUKFTLjjFq2bCnjx483oaddu3amq01nmKkGDRqY9ej5ibp37y67d++WUaNGyciRIx9m0wEAQDz0UOch0plkOvDYu4VFf9cZYNGZZbZ161Z58sknzc3titPfe/fubVqb9ISKr776qjzxxBMm0Ggr0Jo1a3y6s3RafcGCBU0Xmk6317Nle59jKG3atLJkyRITtvTvNazp+plyDwAA/lELkQ4yPnfu3H2P62OXL1+O8npeeOEFcw6jiCxevPiB69CWpGnTpkVaRgdja5ACELE8PRY8sMzRwaGxUhcAiBMtRHp+H+0emz17thnXo7f//ve/phVHp8kDAADE+xYiHa/TpUsXMz5Hx+2YFYWEmECkl8YAAACI94EoRYoUMnbsWBN+dLCz0vMDpUyZ0t/1AwAACO6Lu7oXXNUr3WsYimw8EAAAQLwKRHouIJ3VpbO/dGaXhiKlXWZRnXIPAAAQpwNRx44dzUkOjx07ZrrPXPXq1TNXnwcAAIj3Y4j0vD46JT5Hjhw+j2vX2e+//+6vugEAAARvC9HVq1d9WoZceg0xrgEGAACsCER6eY5vvvnG55plev2woUOHSqVKlfxZPwAAgODsMtPgo4Oq9dIbt27dMtcY27Nnj2khWrdunf9rCQAAEGyBqGjRoubq9qNHjzYXedWLtOoZqtu2beu5Ej2C89ILAADAD4FIz0ytV5jXs1W///770f1zAACAuD+GSKfb61XoAQAArB5U3ahRI/nqq6/8XxsAAIC4Mobozp078vXXX8uyZcukdOnS913DbMSIEf6qHwAAQHAFot9++03y5Mkju3fvllKlSpnHdHC1N52CDwAAEG8DkZ6JWq9btnLlSs+lOj799FPJkiVLTNUPAAAguAJR2KvZL1y40Jy1GkD0cZoEAIjjY4giCkhAoBAuAACxNstMxweFHSPEmCEAAGBdl1mzZs08F3C9ceOGtG7d+r5ZZrNnz/ZvLQEAAIIlEDVt2vS+8xEBAABYFYgmTpwYczUBAACIS2eqBgAAiE8IRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsFxLoCiD45OmxINBVAAAgVtFCBAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWC2gg+umnn6RmzZqSPXt2SZAggXz//fc+yx3Hkd69e0u2bNkkefLkUrVqVTl48KBPmfPnz0vDhg0lTZo0ki5dOmnRooVcuXLFp8zOnTvlueeek2TJkknOnDll6NChsbJ9AAAgbghoILp69aqUKFFCxowZE+5yDS6ffvqpjB8/XjZt2iQpU6aU6tWry40bNzxlNAzt2bNHli5dKvPnzzchq1WrVp7lly5dkmrVqknu3Lll27ZtMmzYMOnbt6988cUXsbKNAAAg+CVwtBkmCGgL0Zw5c6R27drmvlZLW446d+4sXbp0MY9dvHhRsmTJIpMmTZL69evLvn37pHDhwrJlyxZ56qmnTJlFixbJyy+/LCdOnDB/P27cOHn//ffl9OnTkiRJElOmR48epjVq//79Uaqbhqq0adOa59eWqGDFRVkR044ODg10FQAgyqLz+R20Y4iOHDliQox2k7l0o8qWLSsbNmww9/WndpO5YUhp+YQJE5oWJbdMxYoVPWFIaSvTgQMH5O+//w73uW/evGl2ovcNAADEX0EbiDQMKW0R8qb33WX6M3PmzD7LQ0JCJEOGDD5lwluH93OENWjQIBO+3JuOOwIAAPFX0AaiQOrZs6dpXnNvx48fD3SVAACAjYEoa9as5ueZM2d8Htf77jL9efbsWZ/ld+7cMTPPvMuEtw7v5wgradKkpq/R+wYAAOKvoA1EefPmNYFl+fLlnsd0LI+ODSpXrpy5rz8vXLhgZo+5VqxYIffu3TNjjdwyOvPs9u3bnjI6I61AgQKSPn36WN0mAAAQnAIaiPR8Qdu3bzc3dyC1/n7s2DEz66xDhw7y4Ycfyty5c2XXrl3SpEkTM3PMnYlWqFAheemll6Rly5ayefNmWbdunbRr187MQNNyqkGDBmZAtZ6fSKfnz5gxQ0aNGiWdOnUK5KYDAIAgEhLIJ9+6datUqlTJc98NKU2bNjVT67t162bOVaTnFdKWoAoVKphp9XqCRdfUqVNNCKpSpYqZXVa3bl1z7iKXDopesmSJtG3bVkqXLi2ZMmUyJ3v0PlcRAACwW9CchyiYcR4i4H84DxGAuCRenIcIAAAgthCIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWC+iZqgHEP1E5QSgneAQQbGghAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWC8k0BVA1OTpsSDQVQAAIN6ihQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPWYZQYgypjtCCC+ooUIAABYjxYiAEHZ0nR0cGis1AUAFC1EAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWC+pA1LdvX0mQIIHPrWDBgp7lN27ckLZt20rGjBklVapUUrduXTlz5ozPOo4dOyahoaGSIkUKyZw5s3Tt2lXu3LkTgK0BAADBKujPQ1SkSBFZtmyZ535IyP9f5Y4dO8qCBQtk1qxZkjZtWmnXrp3UqVNH1q1bZ5bfvXvXhKGsWbPK+vXr5dSpU9KkSRNJnDixDBw4MCDbAwAAgk/QByINQBpowrp48aJ89dVXMm3aNKlcubJ5bOLEiVKoUCHZuHGjPPPMM7JkyRLZu3evCVRZsmSRkiVLyoABA6R79+6m9SlJkiQB2CIAABBsgrrLTB08eFCyZ88ujz32mDRs2NB0galt27bJ7du3pWrVqp6y2p2WK1cu2bBhg7mvP4sVK2bCkKt69epy6dIl2bNnTwC2BgAABKOgbiEqW7asTJo0SQoUKGC6u/r16yfPPfec7N69W06fPm1aeNKlS+fzNxp+dJnSn95hyF3uLovIzZs3zc2lAQoAAMRfQR2IatSo4fm9ePHiJiDlzp1bZs6cKcmTJ4+x5x00aJAJXwAAwA5B32XmTVuDnnjiCTl06JAZV3Tr1i25cOGCTxmdZeaOOdKfYWeduffDG5fk6tmzpxmj5N6OHz8eI9sDAACCQ5wKRFeuXJHDhw9LtmzZpHTp0ma22PLlyz3LDxw4YMYYlStXztzXn7t27ZKzZ896yixdulTSpEkjhQsXjvB5kiZNasp43wAAQPwV1F1mXbp0kZo1a5puspMnT0qfPn0kUaJE8uabb5pp9i1atJBOnTpJhgwZTGhp3769CUE6w0xVq1bNBJ/GjRvL0KFDzbihXr16mXMXaegBAAAI+kB04sQJE37++usveeSRR6RChQpmSr3+rkaOHCkJEyY0J2TUQdA6g2zs2LGev9fwNH/+fGnTpo0JSilTppSmTZtK//79A7hVAAAg2CRwHMcJdCWCnc4y0xYpHU8UqO6zPD0WBOR5gUA5Ojg00FUAYNHnd5waQwQAABATCEQAAMB6BCIAAGC9oB5UDcBeURk3xzgjAP5CCxEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrhQS6AgDwsPL0WPDAMkcHh8ZKXQDEbbQQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsx3mI4si5VAAAQMyhhQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPWYZQbAelGZ6Xl0cGis1AVAYBCIACAKCE1A/EYgAhCvcZ4vAFHBGCIAAGA9WogAwE/oVgPiLlqIAACA9QhEAADAenSZAUAsolsNCE60EAEAAOtZFYjGjBkjefLkkWTJkknZsmVl8+bNga4SAAAIAtZ0mc2YMUM6deok48ePN2Hok08+kerVq8uBAwckc+bMga4eAMTI+ZXofgOiJoHjOI5YQENQmTJlZPTo0eb+vXv3JGfOnNK+fXvp0aNHpH976dIlSZs2rVy8eFHSpEnj97px4jgA8UGwhS/Ga+FSND6/rWghunXrlmzbtk169uzpeSxhwoRStWpV2bBhQ0DrBgCI+whfcZ8VgejPP/+Uu3fvSpYsWXwe1/v79++/r/zNmzfNzaXJ0k2aMeHezWsxsl4AiE25Os6SuCY26xyV59rdr7rElqJ9Fksw2R0D2+5+bkelM8yKQBRdgwYNkn79+t33uHaxAQAQU9J+ItZKG4PbfvnyZdN1JrYHokyZMkmiRInkzJkzPo/r/axZs95XXrvWdAC2S8cbnT9/XjJmzCgJEiT4R0lVQ9Xx48djZCwSoofjEVw4HsGHYxJcOB7Rpy1DGoayZ8/+wLJWBKIkSZJI6dKlZfny5VK7dm1PyNH77dq1u6980qRJzc1bunTp/FYffSHzYg4eHI/gwvEIPhyT4MLxiJ4HtQxZFYiUtvg0bdpUnnrqKXn66afNtPurV6/KW2+9FeiqAQCAALMmENWrV0/OnTsnvXv3ltOnT0vJkiVl0aJF9w20BgAA9rEmECntHguviyy2aDdcnz597uuOQ2BwPIILxyP4cEyCC8cjZllzYkYAAICIWHUtMwAAgPAQiAAAgPUIRAAAwHoEIgAAYD0CUSwZM2aM5MmTR5IlSyZly5aVzZs3B7pK1lyGpUyZMpI6dWrJnDmzOTHngQMHfMrcuHFD2rZta85EnipVKqlbt+59ZzVHzBg8eLA5+3uHDh08j3E8Yt8ff/whjRo1Mvs8efLkUqxYMdm6datnuc690VOWZMuWzSzXC2MfPHgwoHWOr/S6mx988IHkzZvX7Ot8+fLJgAEDfK7FxfGIGQSiWDBjxgxzYkidLvnzzz9LiRIlpHr16nL27NlAVy3eW716tflw3bhxoyxdulRu374t1apVMyfldHXs2FHmzZsns2bNMuVPnjwpderUCWi9bbBlyxb5/PPPpXjx4j6Pczxi199//y3ly5eXxIkTy8KFC2Xv3r0yfPhwSZ8+vafM0KFD5dNPP5Xx48fLpk2bJGXKlOY9TMMr/GvIkCEybtw4GT16tOzbt8/c1/3/2WefecpwPGKITrtHzHr66aedtm3beu7fvXvXyZ49uzNo0KCA1stGZ8+e1a9ZzurVq839CxcuOIkTJ3ZmzZrlKbNv3z5TZsOGDQGsafx2+fJl5/HHH3eWLl3qPP/88857771nHud4xL7u3bs7FSpUiHD5vXv3nKxZszrDhg3zPKbHKWnSpM53330XS7W0R2hoqNO8eXOfx+rUqeM0bNjQ/M7xiDm0EMWwW7duybZt20yTpithwoTm/oYNGwJaNxtdvHjR/MyQIYP5qcdGW428j0/BggUlV65cHJ8YpK12oaGhPvtdcTxi39y5c80ljd544w3Trfzkk0/Kl19+6Vl+5MgRc3Z/72Oi14bSrn+Oif89++yz5jqbv/76q7m/Y8cOWbt2rdSoUcPc53jEHKvOVB0If/75p+kTDnuJEL2/f//+gNXLRnpBXx2rot0DRYsWNY/pG4te/DfsxXv1+Ogy+N/06dNN17F2mYXF8Yh9v/32m+mi0W79//znP+a4vPvuu+Y46PUf3f0e3nsYx8T/evToYa5qr18EEiVKZD4/PvroI2nYsKFZzvGIOQQiWNUqsXv3bvNtC4Fx/Phxee+998x4Lp1ggOD4oqAtRAMHDjT3tYVI/5/o+BQNRIhdM2fOlKlTp8q0adOkSJEisn37dvNFLnv27ByPGEaXWQzLlCmTSflhZ8no/axZswasXrbRa9jNnz9fVq5cKTly5PA8rsdAuzUvXLjgU57jEzO0S0wnE5QqVUpCQkLMTQdO6wBR/V2/5XI8YpfOVCpcuLDPY4UKFZJjx46Z3939zntY7OjatatpJapfv76Z7de4cWMz0UBnzCqOR8whEMUwbXYuXbq06RP2/kam98uVKxfQutlAp6dqGJozZ46sWLHCTGX1psdGZ9d4Hx+dlq8fBhwf/6tSpYrs2rXLfOt1b9o6od0B7u8cj9ilXchhT0Wh41dy585tftf/M/pB631MtEtHZzdxTPzv2rVrZpypN/1SrZ8biuMRg2JwwDb+P9OnTzczACZNmuTs3bvXadWqlZMuXTrn9OnTga5avNemTRsnbdq0zqpVq5xTp055bteuXfOUad26tZMrVy5nxYoVztatW51y5cqZG2KH9ywzxfGIXZs3b3ZCQkKcjz76yDl48KAzdepUJ0WKFM6UKVM8ZQYPHmzes3744Qdn586dTq1atZy8efM6169fD2jd46OmTZs6jz76qDN//nznyJEjzuzZs51MmTI53bp185TheMQMAlEs+eyzz8ybfJIkScw0/I0bNwa6SlbQzB/ebeLEiZ4y+ibyzjvvOOnTpzcfBK+99poJTQhMIOJ4xL558+Y5RYsWNV/cChYs6HzxxRc+y3Wq9wcffOBkyZLFlKlSpYpz4MCBgNU3Prt06ZL5/6CfF8mSJXMee+wx5/3333du3rzpKcPxiBkJ9J+YbIECAAAIdowhAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEwMfRo0clQYIE5lIaMWXVqlXmOcJes8yf+vbtKyVLloyx9cd3zZo1k9q1awe6GkCsIRAB8ZCGjchuGhYC6dlnn5VTp05J2rRpA/L8uv0P2kexESaCIXTERgAG4oKQQFcAgP9p2HDNmDFDevfu7XMBz1SpUkmgL3ocyCtzd+nSRVq3bu25X6ZMGWnVqpW0bNkyYHUCEFi0EAHxkIYN96atMNoC4N7PnDmzjBgxQnLkyCFJkyY13UqLFi2KcF13796V5s2bS8GCBc1V59UPP/wgpUqVkmTJksljjz0m/fr1kzt37nj+Rp9vwoQJ8tprr0mKFCnk8ccfl7lz50bYZfbCCy+E20qjrRdKy7399tvyyCOPSJo0aaRy5cqyY8cOn3oOHjxYsmTJIqlTp5YWLVrIjRs3ItwmDYTe+0ivJq5/596/ffu2/Otf/5J06dJJhgwZpFatWp667N+/32zTtGnTPOubOXOmJE+eXPbu3WtanyZPnmz2kbsdur0PY/fu3VKjRg1TX922xo0by59//ulZrvvt3XfflW7dupl6at3Dtv5pfStUqGCOVeHChWXZsmWmTt9//73n6unqySefNI/rOr19/PHHki1bNsmYMaO0bdvW7BsgPiIQAZYZNWqUDB8+3HzQ7dy5U6pXry6vvvqqHDx48L6yN2/elDfeeMN0p6xZs0Zy5cplfjZp0kTee+89EwA+//xzmTRpknz00Uc+f6shSUOFPsfLL78sDRs2lPPnz4dbp9mzZ5tWLfdWp04dKVCggAkBSutw9uxZWbhwoWzbts2EsSpVqnjWp4FEg8DAgQNl69at5gN87NixD7V/9ANf94kGJN3WdevWmUDy0ksvya1bt0ww1H33zjvvmIB44sQJ09o0ZMgQEzi09Um3W8u726NdhNGlIVCDnwYV3SYNrWfOnDHr9qbhK2XKlLJp0yYZOnSo9O/fX5YuXeoJs9olpwFOl3/xxRfy/vvv+/z95s2bzU8NSlpXPRaulStXyuHDh81PfR49znoD4qUYumgsgCAxceJEJ23atJ772bNndz766COfMmXKlDFXmFdHjhzRCz47a9asMVfRrlChgnPhwgVPWX1s4MCBPn//7bffOtmyZfPc17/v1auX5/6VK1fMYwsXLjT3V65cae7//fff99V3xIgRTrp06TxX79Z6pEmTxrlx44ZPuXz58jmff/65+b1cuXKe+rvKli3rlChRIkr7KHfu3M7IkSM921KgQAFzRXGXXmk8efLkzuLFiz2PhYaGOs8995zZH9WqVfMp37RpU6dWrVoPfN7Iyg0YMMCs19vx48fNfnP3zfPPP2+OT9hj2b17d/O77u+QkBDn1KlTnuVLly4165gzZ47P8f7ll1/uq5vulzt37ngee+ONN5x69eo9cLuAuIgxRIBFLl26JCdPnpTy5cv7PK73w3ZBvfnmm6ZbbcWKFaY7yKXltNXEu0VIWyK0i+ratWumNUIVL17cs1xbMLSrS1t5IqMtQD169JB58+bJE0884Xm+K1eumC4bb9evXzetF2rfvn0+Y4JUuXLlTMtGdOnzHTp0yLQQedPtc59Pff3116aOCRMmlD179vzjgdjh1UPrH954L62Hu3+897PS1jF3P+u4sZw5c/qM13r66aejXIciRYqY7kTvde/ateuhtgcIdgQiAOHSbq4pU6bIhg0bTNeNS8OJdodpt1ZYOk7FlThxYp9lGhju3bsX4fNp91v9+vXNWKBq1ar5PJ9+EIc3DkfH+PibPl/p0qVl6tSp9y3TMUzegeXq1asmEGlXk9bR3/WoWbOm6YoLy/u5orufoyMm1w0EGwIRYBFtpcmePbtp4Xn++ec9j+v9sC0Hbdq0kaJFi5rxRQsWLPCU1/E72vKQP39+v9VLBwrrh3/dunWlY8eOPsv0+U6fPi0hISGSJ0+ecP++UKFCZoyMjm1ybdy48aHqos+nM/N08Lnur/Do2CWdMq/jcTQM6fion3/+2dOSprPotNXsn9B6/Pe//zXbrNv+MHQc1vHjx83YI3c81pYtW3zKaF3VP60vENcxqBqwTNeuXU2rg37oa7DRLiodNK2DpMNq3769fPjhh/LKK6/I2rVrzWM6hf+bb74xrUTaVaTdVdOnT5devXo9dJ00CGlXmw6M1vDj3vRDumrVqqb7SwcHL1myxMz2Wr9+vQkjOthYad21C2vixIny66+/Sp8+fUzdHoaGm0yZMpmZZTqo+siRI6Z1Smdz6QBqpd1z2hWl26wz9rSeOpjapSFGB5Pr/tWwF9nMrIsXL5r9733TEKMzujR4adelhhjtJlu8eLG89dZbUQ4vL774ouTLl0+aNm1q6qPB1z1ObhefBj8Ncu6gba0PYCMCEWAZ/WDv1KmTdO7cWYoVK2Y+CHVKvE6ND0+HDh1M+NEuNA0iOgNr/vz5Jpzo+XueeeYZGTlypOTOnfuh6/TTTz+ZKea6Du0Ocm8aDPSD+8cff5SKFSuaMKBjZ7Rr7ffff/e0etSrV08++OADM/1cu7t0mbZwPQwNZlofnVGn3YLa+uRO49cWIw2DWp9vv/3WtNzo+CjtWvzyyy/NGCil5zPS1pmnnnrKdLNpEImIhi2dSeZ90/3ttuRp+NEuRD1Weiy0m1C76aJCx//o9HrtftNjpacucGeZud2bug2ffvqpmS2oz6lBELBRAh1ZHehKAABih4YsPS+RDhzX1iMA/0MgAoB4bM6cOWammrYAagjS7sX06dN7ukAB/A+DqgEgHrt8+bJ0797dnERSx0bpmCw9MScAX7QQAQAA6zGoGgAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAACI7f4f2341zMEr6OUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 91\n",
      "Number of samples > 64: 86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis statistic shows that the maximum length of a tokenized text is 91\\nwhile there is only 86 out of 40690 longer than 64.\\nTherefore, choosing a token length of 128 for the data is inefficient,\\nand you will increase the computational power and training time for nothing.\\nBest choice is 64.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths = [len(tokenizer.tokenize(item[\"text\"])) for item in full_data]\n",
    "\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.xlabel(\"Tokenized Text Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Tokenized Text Lengths\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"Number of samples > 64: {sum(l > 64 for l in lengths)}\")\n",
    "\n",
    "\"\"\"\n",
    "This statistic shows that the maximum length of a tokenized text is 91\n",
    "while there is only 86 out of 40690 longer than 64.\n",
    "Therefore, choosing a token length of 128 for the data is inefficient,\n",
    "and you will increase the computational power and training time for nothing.\n",
    "Best choice is 64.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e5d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AspectDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=64):\n",
    "        self.data = data  # Raw data with original text\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Tokenize here with offset mapping\n",
    "        encoding = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "        \n",
    "        # Create BIO labels using the text and offset mapping\n",
    "        labels = self.create_bio_labels(\n",
    "            item[\"text\"], \n",
    "            item[\"aspects\"], \n",
    "            encoding[\"offset_mapping\"][0]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"][0].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"][0].squeeze(),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def create_bio_labels(self, text, aspects, offset_mapping):\n",
    "        \"\"\"\n",
    "        Create BIO labels using character-level offsets\n",
    "        \"\"\"\n",
    "        labels = [0] * len(offset_mapping)  # 0 for 'O' (Outside)\n",
    "        \n",
    "        for aspect in aspects:\n",
    "            aspect_text = aspect[\"term\"]\n",
    "            start_char = aspect[\"from\"]\n",
    "            end_char = aspect[\"to\"]\n",
    "            \n",
    "            # Find tokens that overlap with the aspect span\n",
    "            for token_idx, (start_offset, end_offset) in enumerate(offset_mapping):\n",
    "                if start_offset == 0 and end_offset == 0:  # Special tokens ([CLS], [SEP], [PAD])\n",
    "                    continue\n",
    "                    \n",
    "                # Check if token overlaps with aspect span\n",
    "                if start_offset < end_char and end_offset > start_char:\n",
    "                    if start_offset >= start_char:  # Token starts within aspect\n",
    "                        if labels[token_idx] == 0:  # Not yet labeled\n",
    "                            # Check if this is the first token of the aspect\n",
    "                            is_first_token = True\n",
    "                            for prev_idx in range(token_idx):\n",
    "                                if labels[prev_idx] != 0:  # Previous token is part of an aspect\n",
    "                                    prev_start, prev_end = offset_mapping[prev_idx]\n",
    "                                    if prev_start < end_char and prev_end > start_char:\n",
    "                                        is_first_token = False\n",
    "                                        break\n",
    "                            \n",
    "                            labels[token_idx] = 1 if is_first_token else 2  # 1 for 'B-', 2 for 'I-'\n",
    "                        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24a40936",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(full_data, test_size=0.2, random_state=42)\n",
    "train_dataset = AspectDataset(train_data, tokenizer)\n",
    "test_dataset = AspectDataset(test_data, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78b641",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae702311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)  # O, B-ASP, I-ASP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd084d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "  preds = np.argmax(p.predictions, axis=-1)\n",
    "  labels = p.label_ids\n",
    "\n",
    "  # Convert to BIO tag lists\n",
    "  id2label = {0: \"O\", 1: \"B-ASP\", 2: \"I-ASP\"}\n",
    "  pred_tags = [[id2label[p] for (p, l) in zip(pred, label) if l != -100] for pred, label in zip(preds, labels)]\n",
    "  true_tags = [[id2label[l] for (p, l) in zip(pred, label) if l != -100] for pred, label in zip(preds, labels)]\n",
    "\n",
    "  return {\n",
    "    \"precision\": precision_score(true_tags, pred_tags),\n",
    "    \"recall\": recall_score(true_tags, pred_tags),\n",
    "    \"f1\": f1_score(true_tags, pred_tags),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "745d3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./aspect_extraction_model\",\n",
    "  num_train_epochs=3,\n",
    "  per_device_train_batch_size=8,\n",
    "  per_device_eval_batch_size=8,\n",
    "  eval_strategy=\"epoch\",\n",
    "  save_strategy=\"epoch\",\n",
    "  logging_dir=\"./logs\",\n",
    "  logging_steps=50,\n",
    "  learning_rate=2e-5,\n",
    "  weight_decay=0.01,\n",
    "  report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset=train_dataset,\n",
    "  eval_dataset=test_dataset,\n",
    "  compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d9d44-a084-4210-8bc9-25fbf52a711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\nlp-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12207' max='12207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12207/12207 9:55:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.914484</td>\n",
       "      <td>0.948012</td>\n",
       "      <td>0.930946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.940926</td>\n",
       "      <td>0.964016</td>\n",
       "      <td>0.952331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.953584</td>\n",
       "      <td>0.966440</td>\n",
       "      <td>0.959969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\nlp-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\HP\\anaconda3\\envs\\nlp-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12207, training_loss=0.012176835005095074, metrics={'train_runtime': 35728.3997, 'train_samples_per_second': 2.733, 'train_steps_per_second': 0.342, 'total_flos': 3189678346902528.0, 'train_loss': 0.012176835005095074, 'epoch': 3.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84c1b1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\nlp-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16276' max='16276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16276/16276 3:18:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.953021</td>\n",
       "      <td>0.970029</td>\n",
       "      <td>0.961450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16276, training_loss=0.0009786580096674833, metrics={'train_runtime': 11886.4108, 'train_samples_per_second': 10.954, 'train_steps_per_second': 1.369, 'total_flos': 4252904462536704.0, 'train_loss': 0.0009786580096674833, 'epoch': 4.0})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./aspect_extraction_model\",\n",
    "  num_train_epochs=4,\n",
    "  per_device_train_batch_size=8,\n",
    "  per_device_eval_batch_size=8,\n",
    "  eval_strategy=\"epoch\",\n",
    "  save_strategy=\"epoch\",\n",
    "  logging_dir=\"./logs\",\n",
    "  logging_steps=50,\n",
    "  learning_rate=2e-5,\n",
    "  weight_decay=0.01,\n",
    "  report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset=train_dataset,\n",
    "  eval_dataset=test_dataset,\n",
    "  compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=\"aspect_extraction_model\\checkpoint-12207\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a918aaa",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f40ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"aspect_extraction_model\\checkpoint-12207\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4315c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predictions_to_aspects(text, predictions, offset_mapping, input_ids, tokenizer):\n",
    "  aspects = []\n",
    "  current_aspect = None\n",
    "  \n",
    "  for i, (pred_label, (start_pos, end_pos)) in enumerate(zip(predictions, offset_mapping)):\n",
    "    # Skip special tokens and padding\n",
    "    if start_pos == 0 and end_pos == 0:\n",
    "      continue\n",
    "        \n",
    "    token = tokenizer.decode([input_ids[i]], skip_special_tokens=True)\n",
    "    \n",
    "    if pred_label == 1:  # B- (Beginning of aspect)\n",
    "      # Save previous aspect if exists\n",
    "      if current_aspect is not None:\n",
    "        aspects.append(current_aspect)\n",
    "      \n",
    "      # Start new aspect\n",
    "      current_aspect = {\n",
    "        \"term\": text[start_pos:end_pos],\n",
    "        \"from\": start_pos,\n",
    "        \"to\": end_pos,\n",
    "        \"tokens\": [token]\n",
    "      }\n",
    "        \n",
    "    elif pred_label == 2:  # I- (Inside aspect)\n",
    "      if current_aspect is not None:\n",
    "        # Extend current aspect\n",
    "        current_aspect[\"term\"] = text[current_aspect[\"from\"]:end_pos]\n",
    "        current_aspect[\"to\"] = end_pos\n",
    "        current_aspect[\"tokens\"].append(token)\n",
    "      \n",
    "      else:\n",
    "        current_aspect = {\n",
    "          \"term\": text[start_pos:end_pos],\n",
    "          \"from\": start_pos,\n",
    "          \"to\": end_pos,\n",
    "          \"tokens\": [token]\n",
    "        }\n",
    "        \n",
    "    elif pred_label == 0:  # O (Outside)\n",
    "      # End current aspect if exists\n",
    "      if current_aspect is not None:\n",
    "        aspects.append(current_aspect)\n",
    "        current_aspect = None\n",
    "  \n",
    "  if current_aspect is not None:\n",
    "    aspects.append(current_aspect)\n",
    "  \n",
    "  return aspects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d7e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspects_extraction(text, model, tokenizer, max_length=64):\n",
    "  model.eval()\n",
    "  encoding = tokenizer(\n",
    "    text,\n",
    "    truncation = True,\n",
    "    padding = 'max_length',\n",
    "    max_length = max_length,\n",
    "    return_offsets_mapping = True,\n",
    "    return_tensors = 'pt'\n",
    "  )\n",
    "  input_ids = encoding[\"input_ids\"]\n",
    "  attention_mask = encoding[\"attention_mask\"]\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "    predicted_labels = torch.argmax(outputs.logits, dim=-1) # outputs.logits shape: [1, 64, 3]\n",
    "\n",
    "  aspects = convert_predictions_to_aspects(text,\n",
    "                                           predicted_labels[0].cpu().numpy(),\n",
    "                                           encoding[\"offset_mapping\"][0].cpu().numpy(),\n",
    "                                           input_ids[0].cpu().numpy(),\n",
    "                                           tokenizer)\n",
    "\n",
    "  return aspects\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfae555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(text, aspects):\n",
    "  print(f\"Text: {text}\")\n",
    "  print(f\"Found {len(aspects)} aspects:\")\n",
    "  \n",
    "  for i, aspect in enumerate(aspects, 1):\n",
    "    print(f\"  {i}. '{aspect['term']}'\")\n",
    "      \n",
    "  print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03de03bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Anyway, the owner was fake.\n",
      "Found 1 aspects:\n",
      "  1. 'owner'\n",
      "--------------------------------------------------\n",
      "Text: Owner is pleasant and entertaining.\n",
      "Found 1 aspects:\n",
      "  1. 'Owner'\n",
      "--------------------------------------------------\n",
      "Text: I have never in my life sent back food before, but I simply had to, and the waiter argued with me over this.\n",
      "Found 2 aspects:\n",
      "  1. 'food'\n",
      "  2. 'waiter'\n",
      "--------------------------------------------------\n",
      "Text: Although the restaurant itself is nice, I prefer not to go for the food.\n",
      "Found 1 aspects:\n",
      "  1. 'food'\n",
      "--------------------------------------------------\n",
      "Text: Creamy appetizers--taramasalata, eggplant salad, and Greek yogurt (with cuccumber, dill, and garlic) taste excellent when on warm pitas.\n",
      "Found 5 aspects:\n",
      "  1. 'Creamy appetizers'\n",
      "  2. '--taramasalata'\n",
      "  3. ', eggplant salad'\n",
      "  4. 'Greek yogurt (with cuccumber, dill, and garlic'\n",
      "  5. 'warm pitas'\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\testing and evaluation\\Restaurants_Test_Data_PhaseA.csv\")\n",
    "test_data = test_data.tail(5)\n",
    "for _ , row in test_data.iterrows():\n",
    "  aspects = aspects_extraction(row['Sentence'], model, tokenizer)\n",
    "  format_output(row['Sentence'], aspects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-env)",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
